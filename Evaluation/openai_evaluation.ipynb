{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LNpRlRbQcvh",
        "outputId": "a5492b01-dce3-49ba-89a6-b4dd19941469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoxzuDUbQlG1",
        "outputId": "35396bc6-077c-47cc-9357-2e3998c51027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "folder_path='/content/drive/MyDrive/CoTRL/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sYXSI3XuOoVb",
        "outputId": "68ba7a7d-a2d7-412b-e174-8f798fe966f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n",
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/300 [00:08<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n",
            "error\n",
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8f3ff923023b>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mans2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# score = openai(query)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_bpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mscores1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-8f3ff923023b>\u001b[0m in \u001b[0;36mget_eval\u001b[0;34m(ques, ans1, ans2)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-8f3ff923023b>\u001b[0m in \u001b[0;36mget_gpt\u001b[0;34m(system_prompt, uer_prompt)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_API_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m--> 288\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_create_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    597\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    791\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "MAX_API_RETRY = 10000\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def gen_prompt(ques, ans1, ans2):\n",
        "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
        "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
        "    default_prompt =  \"\"\"We would like to request your feedback on the performance of two AI assistants in response to the user question displayed above.\n",
        "    Please rate the helpfulness, relevance, accuracy, level of details of their responses.\n",
        "\n",
        "    Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
        "    Please first provide a precise and short explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.\n",
        "    Then, output two lines indicating the scores for Assistant 1 and 2, respectively.\n",
        "\n",
        "    Output with the following format:\n",
        "    Evaluation evidence: <your evluation explanation here>\n",
        "    Score of the Assistant 1: <score>\n",
        "    Score of the Assistant 2: <score>\"\"\"\n",
        "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
        "\n",
        "\n",
        "def get_eval(ques, ans1, ans2):\n",
        "    system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
        "    response = get_gpt(system_prompt, user_prompt)\n",
        "    all_scores = []\n",
        "    contents = []\n",
        "    contents_bpc = []\n",
        "    try:\n",
        "        for choice in response[\"choices\"]:\n",
        "            content = choice[\"message\"][\"content\"]\n",
        "            score1, score2 = parse_score_from_review(content)\n",
        "            if score1 == -1 or score2 == -1:\n",
        "                continue\n",
        "            all_scores.append([score1, score2])\n",
        "            contents.append(content)\n",
        "    except:\n",
        "        print(response)\n",
        "\n",
        "    system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
        "    response_bpc = get_gpt(system_prompt, user_prompt_bpc)\n",
        "    try:\n",
        "        for choice in response_bpc[\"choices\"]:\n",
        "            content = choice[\"message\"][\"content\"]\n",
        "            score2, score1 = parse_score_from_review(content)\n",
        "            if score1 == -1 or score2 == -1:\n",
        "                continue\n",
        "            all_scores.append([score1, score2])\n",
        "            contents_bpc.append(content)\n",
        "    except:\n",
        "        print(response)\n",
        "    try:\n",
        "      score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
        "      score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
        "    except:\n",
        "      score1 = -1\n",
        "      score2 = -1\n",
        "    return contents, contents_bpc, [score1, score2]\n",
        "\n",
        "\n",
        "def parse_score_from_review(review):\n",
        "    try:\n",
        "        score1 = review.split(\"\\n\")[-2]\n",
        "        score2 = review.split(\"\\n\")[-1]\n",
        "        score1 = score1.split(\":\")[-1].strip()\n",
        "        score2 = score2.split(\":\")[-1].strip()\n",
        "        return [float(score1), float(score2)]\n",
        "    except:\n",
        "        print(f'Failed to parse scores from {review}')\n",
        "        return [-1, -1]\n",
        "\n",
        "\n",
        "def get_question(datapoint):\n",
        "    question = datapoint[\"goal\"]\n",
        "    option1 = datapoint[\"sol1\"]\n",
        "    option2 = datapoint[\"sol2\"]\n",
        "    special = '\\n'\n",
        "    # query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "    query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}\"\n",
        "    return query\n",
        "\n",
        "\n",
        "def get_answer(datapoint):\n",
        "    option2 = datapoint[\"sol2\"]\n",
        "    special = '\\n'\n",
        "    return f\"{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "\n",
        "\n",
        "def get_gpt(system_prompt, uer_prompt):\n",
        "    for i in range(MAX_API_RETRY):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": uer_prompt},\n",
        "                ],\n",
        "                temperature=1,\n",
        "                max_tokens=512,\n",
        "                n=3\n",
        "            )\n",
        "            return response\n",
        "        except openai.error.RateLimitError:\n",
        "            print('rate limit')\n",
        "            time.sleep(30)\n",
        "        except Exception as e:\n",
        "            print('error')\n",
        "    raise RuntimeError(f\"Failed after {MAX_API_RETRY} retries.\")\n",
        "\n",
        "\n",
        "\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/piqa_test/10000_training.csv\")\n",
        "scores1 = []\n",
        "scores2 = []\n",
        "contents = []\n",
        "content_bpcs = []\n",
        "\n",
        "\n",
        "\n",
        "# for i in [\"20000\", \"30000\", \"40000\", \"50000\"]:\n",
        "for i in [\"30000\", \"40000\", \"50000\"]:\n",
        "    dataset_dir = f\"/content/drive/MyDrive/CoTRL/piqa_test/{i}_training.csv\"\n",
        "    save_dir = dataset_dir.replace(\"dataset\", \"result\").replace(\"training\", \"vs_10000_result\")\n",
        "    df = pd.read_csv(dataset_dir)[:300]\n",
        "\n",
        "    # df['query'] = df.apply(get_query, axis=1)\n",
        "\n",
        "    for i in tqdm(range(len(df))):\n",
        "        ques = get_question(df.iloc[i])\n",
        "        ans1 = get_answer(df.iloc[i])\n",
        "        ans2 = get_answer(df_ref.iloc[i])\n",
        "        # score = openai(query)\n",
        "        content, content_bpc, [score1, score2] = get_eval(ques, ans1, ans2)\n",
        "        try:\n",
        "            scores1.append(float(score1))\n",
        "            scores2.append(float(score2))\n",
        "            contents.append(content)\n",
        "            content_bpcs.append(content_bpc)\n",
        "        except:\n",
        "            scores1.append(- float(\"inf\"))\n",
        "            scores2.append(- float(\"inf\"))\n",
        "            contents.append('[invalid]')\n",
        "            content_bpcs.append('[invalid]')\n",
        "\n",
        "\n",
        "    df[\"score1\"] = scores1\n",
        "    df[\"score2\"] = scores2\n",
        "    df[\"content\"] = contents\n",
        "    df[\"content_bpcs\"] = content_bpcs\n",
        "    df.to_csv(save_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
        "                    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "                ],\n",
        "                temperature=1,\n",
        "                max_tokens=512,\n",
        "                n=3\n",
        "            )"
      ],
      "metadata": {
        "id": "CLUt_taEYwQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_score = pd.read_csv(\"/content/drive/MyDrive/CoTRL/piqa_test/20000_vs_10000_result.csv\")"
      ],
      "metadata": {
        "id": "4Dbrq36IXfWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df_score[\"score1\"] - df_score[\"score2\"]).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BTvNgOcX7dB",
        "outputId": "f2152f68-0b01-4fd1-c54d-f96eaf5dc95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.008611111111111146"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parse_score_from_review(\"Evaluation evidence: Both Assistant 1 and Assistant 2 provide relevant and accurate answers to the question. They correctly mention the necessary items like bedding, water bottle, and food dish. However, Assistant 1 provides a more precise and specific answer by suggesting ripped paper strips as the bedding material, which is more commonly used for guinea pigs compared to ripped jeans material mentioned by Assistant 2. Therefore, Assistant 1's answer is more helpful and detailed.\\n\\nScore of Assistant 1: 8.5\\nScore of Assistant 2: 7.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtU0AMEHZ9Kj",
        "outputId": "7a5c8ea7-c4c9-4267-9cee-880f2be516b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.5, 7.5]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUQbM_usAz8X",
        "outputId": "2bf0bc75-d66d-4697-ecc6-6a970549eec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/CoTRL/data/test_3000_svamp.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/CoTRL/data/test_base_svamp.csv')"
      ],
      "metadata": {
        "id": "KAYBJHwNAtpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "MAX_API_RETRY = 10000\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def gen_prompt(ques, ans1, ans2):\n",
        "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
        "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
        "    default_prompt =  \"\"\"We would like to request your feedback on the performance of two AI assistants in response to the user question displayed above.\n",
        "    Please rate the helpfulness, relevance, accuracy, level of details of their responses.\n",
        "\n",
        "    Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
        "    Please first provide a precise and short explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.\n",
        "    Then, output two lines indicating the scores for Assistant 1 and 2, respectively.\n",
        "\n",
        "    Output with the following format:\n",
        "    Evaluation evidence: <your evluation explanation here>\n",
        "    Score of the Assistant 1: <score>\n",
        "    Score of the Assistant 2: <score>\"\"\"\n",
        "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
        "\n",
        "\n",
        "def get_eval(ques, ans1, ans2):\n",
        "    system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
        "    response = get_gpt(system_prompt, user_prompt)\n",
        "    all_scores = []\n",
        "    contents = []\n",
        "    contents_bpc = []\n",
        "    try:\n",
        "        for choice in response[\"choices\"]:\n",
        "            content = choice[\"message\"][\"content\"]\n",
        "            score1, score2 = parse_score_from_review(content)\n",
        "            if score1 == -1 or score2 == -1:\n",
        "                continue\n",
        "            all_scores.append([score1, score2])\n",
        "            contents.append(content)\n",
        "    except:\n",
        "        print(response)\n",
        "\n",
        "    system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
        "    response_bpc = get_gpt(system_prompt, user_prompt_bpc)\n",
        "    try:\n",
        "        for choice in response_bpc[\"choices\"]:\n",
        "            content = choice[\"message\"][\"content\"]\n",
        "            score2, score1 = parse_score_from_review(content)\n",
        "            if score1 == -1 or score2 == -1:\n",
        "                continue\n",
        "            all_scores.append([score1, score2])\n",
        "            contents_bpc.append(content)\n",
        "    except:\n",
        "        print(response)\n",
        "    try:\n",
        "      score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
        "      score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
        "    except:\n",
        "      score1 = -1\n",
        "      score2 = -1\n",
        "    return contents, contents_bpc, [score1, score2]\n",
        "\n",
        "\n",
        "def parse_score_from_review(review):\n",
        "    try:\n",
        "        score1 = review.split(\"\\n\")[-2]\n",
        "        score2 = review.split(\"\\n\")[-1]\n",
        "        score1 = score1.split(\":\")[-1].strip()\n",
        "        score2 = score2.split(\":\")[-1].strip()\n",
        "        return [float(score1), float(score2)]\n",
        "    except:\n",
        "        print(f'Failed to parse scores from {review}')\n",
        "        return [-1, -1]\n",
        "\n",
        "\n",
        "def get_question(datapoint):\n",
        "    question = datapoint[\"goal\"]\n",
        "    option1 = datapoint[\"sol1\"]\n",
        "    option2 = datapoint[\"sol2\"]\n",
        "    special = '\\n'\n",
        "    # query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "    query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}\"\n",
        "    return query\n",
        "\n",
        "\n",
        "def get_answer(datapoint):\n",
        "    option2 = datapoint[\"sol2\"]\n",
        "    special = '\\n'\n",
        "    return f\"{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "\n",
        "\n",
        "def get_gpt(system_prompt, uer_prompt):\n",
        "    for i in range(MAX_API_RETRY):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": uer_prompt},\n",
        "                ],\n",
        "                temperature=1,\n",
        "                max_tokens=512,\n",
        "                n=3\n",
        "            )\n",
        "            return response\n",
        "        except openai.error.RateLimitError:\n",
        "            print('rate limit')\n",
        "            time.sleep(30)\n",
        "        except Exception as e:\n",
        "            print('error')\n",
        "    raise RuntimeError(f\"Failed after {MAX_API_RETRY} retries.\")\n",
        "\n",
        "\n",
        "\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/piqa_test/10000_training.csv\")\n",
        "scores1 = []\n",
        "scores2 = []\n",
        "contents = []\n",
        "content_bpcs = []\n",
        "\n",
        "\n",
        "\n",
        "# for i in [\"20000\", \"30000\", \"40000\", \"50000\"]:\n",
        "for i in [\"30000\", \"40000\", \"50000\"]:\n",
        "    dataset_dir = f\"/content/drive/MyDrive/CoTRL/piqa_test/{i}_training.csv\"\n",
        "    save_dir = dataset_dir.replace(\"dataset\", \"result\").replace(\"training\", \"vs_10000_result\")\n",
        "    df = pd.read_csv(dataset_dir)[:300]\n",
        "\n",
        "    # df['query'] = df.apply(get_query, axis=1)\n",
        "\n",
        "    for i in tqdm(range(len(df))):\n",
        "        ques = get_question(df.iloc[i])\n",
        "        ans1 = get_answer(df.iloc[i])\n",
        "        ans2 = get_answer(df_ref.iloc[i])\n",
        "        # score = openai(query)\n",
        "        content, content_bpc, [score1, score2] = get_eval(ques, ans1, ans2)\n",
        "        try:\n",
        "            scores1.append(float(score1))\n",
        "            scores2.append(float(score2))\n",
        "            contents.append(content)\n",
        "            content_bpcs.append(content_bpc)\n",
        "        except:\n",
        "            scores1.append(- float(\"inf\"))\n",
        "            scores2.append(- float(\"inf\"))\n",
        "            contents.append('[invalid]')\n",
        "            content_bpcs.append('[invalid]')\n",
        "\n",
        "\n",
        "    df[\"score1\"] = scores1\n",
        "    df[\"score2\"] = scores2\n",
        "    df[\"content\"] = contents\n",
        "    df[\"content_bpcs\"] = content_bpcs\n",
        "    df.to_csv(save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "1hV7OnasBIBe",
        "outputId": "cd973ada-9fce-49e1-bc29-edc97916f67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8f3ff923023b>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mdf_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/CoTRL/piqa_test/10000_training.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0mscores1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mscores2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CoTRL/piqa_test/10000_training.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/CoTRL/piqa_test/30000_vs_10000_result.csv\")\n",
        "df['score1'] > df['score2']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pBViujKB6rs",
        "outputId": "e5bea91e-90a6-482d-97aa-adbbcfb3abe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       False\n",
              "1        True\n",
              "2       False\n",
              "3       False\n",
              "4        True\n",
              "        ...  \n",
              "1833    False\n",
              "1834    False\n",
              "1835    False\n",
              "1836    False\n",
              "1837     True\n",
              "Length: 1838, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(datapoint):\n",
        "    option2 = datapoint[\"sol2\"]\n",
        "    special = '\\n'\n",
        "    return f\"{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "def extract_answer(text):\n",
        "    # 使用正则表达式来提取答案中的数字部分\n",
        "    match = re.search(r'sol \\[(\\d+)\\]', text)\n",
        "\n",
        "    if match:\n",
        "        answer = match.group(1)  # 使用 group(1) 提取括号内的内容（数字部分）\n",
        "        return int(answer)\n",
        "    else:\n",
        "        return \"未找到答案\"\n",
        "def gen_prompt(ques, ans1, ans2):\n",
        "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
        "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
        "    default_prompt =  \"\"\"We would like to request your feedback on the performance of two AI assistants in response to the user question displayed above.\n",
        "    Please rate the helpfulness, relevance, accuracy, level of details of their responses.\n",
        "\n",
        "    Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
        "    Please first provide a precise and short explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.\n",
        "    Then, output two lines indicating the scores for Assistant 1 and 2, respectively.\n",
        "\n",
        "    Output with the following format:\n",
        "    Evaluation evidence: <your evluation explanation here>\n",
        "    Score of the Assistant 1: <score>\n",
        "    Score of the Assistant 2: <score>\"\"\"\n",
        "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/piqa_test/10000_training.csv\")\n",
        "df_all = pd.DataFrame()\n",
        "df_all[0] = df.apply(get_answer, axis=1).apply(extract_answer)\n",
        "df_all[1] = df_ref.apply(get_answer, axis=1).apply(extract_answer)\n",
        "df_all['label1'] = df['label'] + 1\n",
        "df_all['label2'] = df_ref['label'] + 1"
      ],
      "metadata": {
        "id": "HaP9eWqTFLxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all[df_all[0] != df_all[1]]\n",
        "# def get_question(datapoint):\n",
        "#     question = datapoint[\"goal\"]\n",
        "#     option1 = datapoint[\"sol1\"]\n",
        "#     option2 = datapoint[\"sol2\"]\n",
        "#     special = '\\n'\n",
        "#     # query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "#     query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}\"\n",
        "#     return query\n",
        "\n",
        "\n",
        "# def get_answer(datapoint):\n",
        "#     option2 = datapoint[\"sol2\"]\n",
        "#     special = '\\n'\n",
        "#     return f\"{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "# df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KP1l3D7dHGuk",
        "outputId": "77350445-aa1f-439e-b04e-9c263c0906a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0  1  label1  label2\n",
              "4    2  1       1       1\n",
              "12   1  2       2       2\n",
              "17   2  1       2       2\n",
              "20   1  2       1       1\n",
              "26   2  1       2       2\n",
              "49   1  2       2       2\n",
              "76   2  1       1       1\n",
              "87   1  2       2       2\n",
              "93   2  1       2       2\n",
              "100  1  2       1       1\n",
              "117  2  1       2       2\n",
              "134  1  2       1       1\n",
              "142  2  1       2       2\n",
              "146  1  2       2       2\n",
              "156  2  1       2       2\n",
              "158  1  2       2       2\n",
              "161  1  2       2       2\n",
              "162  1  2       2       2\n",
              "168  1  2       2       2\n",
              "175  2  1       2       2\n",
              "180  1  2       1       1\n",
              "183  2  1       1       1\n",
              "196  1  2       1       1\n",
              "210  2  1       2       2\n",
              "212  1  2       1       1\n",
              "236  1  2       1       1\n",
              "240  1  2       2       2\n",
              "243  1  2       1       1\n",
              "248  2  1       2       2\n",
              "254  1  2       2       2\n",
              "271  2  1       1       1\n",
              "280  1  2       1       1\n",
              "298  1  2       1       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45eeb432-1626-4403-9899-e34950f6c1af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45eeb432-1626-4403-9899-e34950f6c1af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45eeb432-1626-4403-9899-e34950f6c1af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45eeb432-1626-4403-9899-e34950f6c1af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d70cb5a9-cc58-4150-9ce4-9149f16654d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d70cb5a9-cc58-4150-9ce4-9149f16654d1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d70cb5a9-cc58-4150-9ce4-9149f16654d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 17\n",
        "ques = get_question(df.iloc[i])\n",
        "ans1 = get_answer(df.iloc[i])\n",
        "ans2 = get_answer(df_ref.iloc[i])\n",
        "print(gen_prompt(ques, ans1, ans2)[1])\n",
        "# print(\"\\n\\n\".join(eval(df[\"content\"][i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EO1L19QHtvO",
        "outputId": "f3d25c5a-41c8-4ea0-e0b0-de8f146fb2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Question]\n",
            "The question is:\n",
            "How do you properly prepare a steak.\n",
            "sol [1]: Take the steak out of warm storage and let come to room temperature, generously add salt and pepper to both sides and let sit for 10 minutes.\n",
            "sol [2]: Take the steak out of cold storage and let come to room temperature, generously add salt and pepper to both sides and let sit for 10 minutes.\n",
            "\n",
            "[The Start of Assistant 1's Answer]\n",
            "\n",
            "\n",
            "Thought: Properly preparing a steak involves ensuring that it reaches the desired temperature and seasoning it appropriately. Both solutions are viable options, but taking the steak out of cold storage and letting it come to room temperature may result in a more even cooking temperature throughout the meat.\n",
            "\n",
            "Therefore, the answer is sol [2]\n",
            "[The End of Assistant 1's Answer]\n",
            "\n",
            "[The Start of Assistant 2's Answer]\n",
            "\n",
            "\n",
            "Thought: Properly preparing a steak involves ensuring that it reaches the desired internal temperature and texture. This can be achieved by letting it come to room temperature before cooking, seasoning it generously, and allowing it to sit for a few minutes to allow the seasonings to penetrate.\n",
            "\n",
            "Therefore, the answer is sol [1]\n",
            "[The End of Assistant 2's Answer]\n",
            "\n",
            "[System]\n",
            "We would like to request your feedback on the performance of two AI assistants in response to the user question displayed above.\n",
            "    Please rate the helpfulness, relevance, accuracy, level of details of their responses.\n",
            "\n",
            "    Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
            "    Please first provide a precise and short explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.\n",
            "    Then, output two lines indicating the scores for Assistant 1 and 2, respectively.\n",
            "\n",
            "    Output with the following format:\n",
            "    Evaluation evidence: <your evluation explanation here>\n",
            "    Score of the Assistant 1: <score>\n",
            "    Score of the Assistant 2: <score>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df['score1'] > df['score2']).sum() / len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgtZ8acejkhJ",
        "outputId": "31012726-a997-4ec5-827c-29a952b354c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3737758433079434"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/CoTRL/piqa_test/30000_vs_10000_result.csv\")\n",
        "df['score1'] > df['score2']\n",
        "(df['score1'] > df['score2']).sum() / len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89QsRkLHDA2L",
        "outputId": "2479d426-579e-4256-e48d-8ad64de478f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3737758433079434"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "\n",
        "MAX_API_RETRY = 10000\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def gen_prompt(ques, ans1, ans2):\n",
        "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
        "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
        "    default_prompt = \"\"\"Please evaluate the quality of the immediate steps to solve the following math problem:\\n\\nEvaluate the clarity, correctness, and completeness of the steps and provided an overall score on a scale of 1 to 10, where 1 is poor and 10 is excellent.\\nEach assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\\n\\nEvaluation criteria:\\n\\nClarity: How easy to understand are the steps?\\nCorrectness: Are the steps accurate and mathematically sound?\\nCompleteness: Do the steps cover all necessary aspects of solving the problem?\\n\\nOutput with the following format:\\nEvaluation evidence: <your evluation explanation here>\\nScore of the Assistant 1: <Float: score>\\nScore of the Assistant 2: <Float: score>. Notice that you should follow the format strictly.\"\"\"\n",
        "    # default_prompt = \"\"\"Please assign scores between 1 and 10 to each assistant based onthe criteria of clarity, correctness, and completeness.\\n\\n Use the following format to present your scores.\\n\\n Score of Assistant 1: <score>\\n\\n Score of Assistant 2: <score>\\n\\nNote: Strictly adhere to the above format while providing the scores.\"\"\"\n",
        "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
        "\n",
        "\n",
        "# def get_eval(ques, ans1, ans2):\n",
        "#     system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
        "#     response = get_gpt(system_prompt, user_prompt)\n",
        "#     print(response)\n",
        "#     all_scores = []\n",
        "#     contents = []\n",
        "#     contents_bpc = []\n",
        "#     try:\n",
        "#         for choice in response[\"choices\"]:\n",
        "#             content = choice[\"message\"][\"content\"]\n",
        "#             score1, score2 = parse_score_from_review(content)\n",
        "#             if score1 == -1 or score2 == -1:\n",
        "#                 continue\n",
        "#             all_scores.append([score1, score2])\n",
        "#             contents.append(content)\n",
        "#     except:\n",
        "#         print(response)\n",
        "\n",
        "#     system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
        "#     response_bpc = get_gpt(system_prompt, user_prompt_bpc)\n",
        "#     try:\n",
        "#         for choice in response_bpc[\"choices\"]:\n",
        "#             content = choice[\"message\"][\"content\"]\n",
        "#             score2, score1 = parse_score_from_review(content)\n",
        "#             if score1 == -1 or score2 == -1:\n",
        "#                 continue\n",
        "#             all_scores.append([score1, score2])\n",
        "#             contents_bpc.append(content)\n",
        "#     except:\n",
        "#         print(response)\n",
        "#     try:\n",
        "#       score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
        "#       score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
        "#       print('%%%%%%%%%%%',score_1,score_2)\n",
        "#     except:\n",
        "#       score1 = -1\n",
        "#       score2 = -1\n",
        "#     return contents, contents_bpc, [score1, score2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_eval(ques, ans1, ans2):\n",
        "    system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
        "    response = get_gpt(system_prompt, user_prompt)\n",
        "    all_scores = []\n",
        "    contents = []\n",
        "    contents_bpc = []\n",
        "    try:\n",
        "      for choice in response[\"choices\"]:\n",
        "          content = choice[\"message\"][\"content\"]\n",
        "          score1, score2 = parse_score_from_review(content)\n",
        "          if score1 == -1 or score2 == -1:\n",
        "              continue\n",
        "          all_scores.append([score1, score2])\n",
        "          contents.append(content)\n",
        "    except:\n",
        "      print(response)\n",
        "\n",
        "    system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
        "    response_bpc = get_gpt(system_prompt, user_prompt_bpc)\n",
        "    try:\n",
        "        for choice in response_bpc[\"choices\"]:\n",
        "            content = choice[\"message\"][\"content\"]\n",
        "            score2, score1 = parse_score_from_review(content)\n",
        "            if score1 == -1 or score2 == -1:\n",
        "                continue\n",
        "            all_scores.append([score1, score2])\n",
        "            contents_bpc.append(content)\n",
        "    except:\n",
        "        print(response)\n",
        "    try:\n",
        "      score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
        "      score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
        "    except:\n",
        "      score1 = -1\n",
        "      score2 = -1\n",
        "    return contents, contents_bpc, [score1, score2]\n",
        "\n",
        "\n",
        "def parse_score_from_review(review):\n",
        "    try:\n",
        "      # Define a regular expression pattern to match the score of Assistant 1 with or without \"the\"\n",
        "      pattern = r\"Score of (?:the )?Assistant 1: (\\d+(?:\\.\\d+)?)\"\n",
        "\n",
        "      # Use the search method to find the first match\n",
        "      match = re.search(pattern, review)\n",
        "\n",
        "      # Initialize score1 as None\n",
        "      score1 = None\n",
        "\n",
        "      # If a match is found, extract and convert the score to float\n",
        "      if match:\n",
        "          score1 = float(match.group(1))\n",
        "\n",
        "      # Define a regular expression pattern to match the score of Assistant 1 with or without \"the\"\n",
        "      pattern = r\"Score of (?:the )?Assistant 2: (\\d+(?:\\.\\d+)?)\"\n",
        "\n",
        "      # Use the search method to find the first match\n",
        "      match = re.search(pattern, review)\n",
        "\n",
        "      # Initialize score1 as None\n",
        "      score2 = None\n",
        "\n",
        "      # If a match is found, extract and convert the score to float\n",
        "      if match:\n",
        "          score2 = float(match.group(1))\n",
        "      return [score1, score2]\n",
        "\n",
        "    except:\n",
        "      print(f'Failed to parse scores from {review}')\n",
        "      return [-1, -1]\n",
        "\n",
        "\n",
        "# def get_question(datapoint):\n",
        "#     question = datapoint[\"goal\"]\n",
        "#     option1 = datapoint[\"sol1\"]\n",
        "#     option2 = datapoint[\"sol2\"]\n",
        "#     special = '\\n'\n",
        "#     # query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "#     query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}\"\n",
        "#     return query\n",
        "\n",
        "\n",
        "# def get_answer(datapoint):\n",
        "#     option2 = datapoint[\"sol2\"]\n",
        "#     special = '\\n'\n",
        "#     return f\"{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "\n",
        "\n",
        "def get_question(datapoint):\n",
        "  question = datapoint[\"Question\"]\n",
        "  return question\n",
        "\n",
        "\n",
        "def get_answer(datapoint):\n",
        "  answer = datapoint[\"Response\"]\n",
        "  return answer\n",
        "\n",
        "\n",
        "def get_gpt(system_prompt, uer_prompt):\n",
        "    for i in range(MAX_API_RETRY):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": uer_prompt},\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=512,\n",
        "                n=1\n",
        "            )\n",
        "            time.sleep(1)\n",
        "            return response\n",
        "        except openai.error.RateLimitError:\n",
        "            print('rate limit')\n",
        "            time.sleep(30)\n",
        "        except Exception as e:\n",
        "            print('error')\n",
        "    raise RuntimeError(f\"Failed after {MAX_API_RETRY} retries.\")\n",
        "\n",
        "\n",
        "\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_base_svamp.csv\")\n",
        "scores1 = []\n",
        "scores2 = []\n",
        "contents = []\n",
        "content_bpcs = []\n",
        "\n",
        "\n",
        "\n",
        "# for i in [\"20000\", \"30000\", \"40000\", \"50000\"]:\n",
        "dataset_dir = f\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_new_svamp.csv\"\n",
        "save_dir = dataset_dir.replace(\"dataset\", \"result\").replace(\"_svamp\", \"_svamp_gpt-4\")\n",
        "df = pd.read_csv(dataset_dir)\n",
        "\n",
        "# df['query'] = df.apply(get_query, axis=1)\n",
        "\n",
        "for i in tqdm(range(len(df))):\n",
        "  ques = get_question(df.iloc[i])\n",
        "  ans1 = get_answer(df.iloc[i])\n",
        "  ans2 = get_answer(df_ref.iloc[i])\n",
        "  # score = openai(query)\n",
        "  content, content_bpc, [score1, score2] = get_eval(ques, ans1, ans2)\n",
        "  try:\n",
        "    scores1.append(float(score1))\n",
        "    scores2.append(float(score2))\n",
        "    contents.append(content)\n",
        "    content_bpcs.append(content_bpc)\n",
        "  except:\n",
        "    scores1.append(- float(\"inf\"))\n",
        "    scores2.append(- float(\"inf\"))\n",
        "    contents.append('[invalid]')\n",
        "    content_bpcs.append('[invalid]')\n",
        "\n",
        "df[\"score1\"] = scores1\n",
        "df[\"score2\"] = scores2\n",
        "df[\"content\"] = contents\n",
        "df[\"content_bpcs\"] = content_bpcs\n",
        "df.to_csv(save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcsKo2suD4jI",
        "outputId": "50a9c835-2759-4959-b07c-9ec14eaf4ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 93/300 [44:52<1:46:00, 30.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 276/300 [2:24:22<11:54, 29.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [2:36:18<00:00, 31.26s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "\n",
        "MAX_API_RETRY = 10000\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def gen_prompt(ques, ans1, ans2):\n",
        "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
        "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
        "    # default_prompt = \"\"\"Please assign scores between 1 and 10 to each assistant based on the criteria of clarity, correctness, and completeness.\\n\\nUse the following format to present your scores.\\n\\nClarity score of Assistant 1: <clarity_score>\\nCorrectness score of Assistant 1: <correctness_score>\\nCompleteness score of Assistant 1: <completeness_score>\\n\\nClarity score of Assistant 2: <clarity_score>\\nCorrectness score of Assistant 2: <correctness_score>\\nCompleteness score of Assistant 2: <completeness_score>\\n\\n\"\"\"\n",
        "    default_prompt = \"\"\"Please evaluate the quality of the immediate steps to solve the following math problem:\\n\\nEvaluate the clarity, correctness, and completeness of the steps and provided an overall score on a scale of 1 to 10, where 1 is poor and 10 is excellent.\\nEach assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\\n\\nEvaluation criteria:\\n\\nClarity: How easy to understand are the steps?\\nCorrectness: Are the steps accurate and mathematically sound?\\nCompleteness: Do the steps cover all necessary aspects of solving the problem?\\n\\nOutput with the following format:\\nEvaluation evidence: <your evluation explanation here>\\nScore of the Assistant 1: <Float: score>\\nScore of the Assistant 2: <Float: score>. Notice that you should follow the format strictly.\"\"\"\n",
        "    # default_prompt = \"\"\"Please assign scores between 1 and 10 to each assistant based onthe criteria of clarity, correctness, and completeness.\\n\\n Use the following format to present your scores.\\n\\n Score of Assistant 1: <score>\\n\\n Score of Assistant 2: <score>\\n\\nNote: Strictly adhere to the above format while providing the scores.\"\"\"\n",
        "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
        "\n",
        "\n",
        "# def get_eval(ques, ans1, ans2):\n",
        "#     system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
        "#     response = get_gpt(system_prompt, user_prompt)\n",
        "#     print(response)\n",
        "#     all_scores = []\n",
        "#     contents = []\n",
        "#     contents_bpc = []\n",
        "#     try:\n",
        "#         for choice in response[\"choices\"]:\n",
        "#             content = choice[\"message\"][\"content\"]\n",
        "#             score1, score2 = parse_score_from_review(content)\n",
        "#             if score1 == -1 or score2 == -1:\n",
        "#                 continue\n",
        "#             all_scores.append([score1, score2])\n",
        "#             contents.append(content)\n",
        "#     except:\n",
        "#         print(response)\n",
        "\n",
        "#     system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
        "#     response_bpc = get_gpt(system_prompt, user_prompt_bpc)\n",
        "#     try:\n",
        "#         for choice in response_bpc[\"choices\"]:\n",
        "#             content = choice[\"message\"][\"content\"]\n",
        "#             score2, score1 = parse_score_from_review(content)\n",
        "#             if score1 == -1 or score2 == -1:\n",
        "#                 continue\n",
        "#             all_scores.append([score1, score2])\n",
        "#             contents_bpc.append(content)\n",
        "#     except:\n",
        "#         print(response)\n",
        "#     try:\n",
        "#       score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
        "#       score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
        "#       print('%%%%%%%%%%%',score_1,score_2)\n",
        "#     except:\n",
        "#       score1 = -1\n",
        "#       score2 = -1\n",
        "#     return contents, contents_bpc, [score1, score2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_eval(ques, ans1, ans2):\n",
        "    system_prompt, user_prompt = gen_prompt(ques, ans1, ans2)\n",
        "    response = get_gpt(system_prompt, user_prompt)\n",
        "    all_scores = []\n",
        "    contents = []\n",
        "    contents_bpc = []\n",
        "    try:\n",
        "      for choice in response[\"choices\"]:\n",
        "          content = choice[\"message\"][\"content\"]\n",
        "          score1, score2 = parse_score_from_review(content)\n",
        "          if score1 == -1 or score2 == -1:\n",
        "              continue\n",
        "          all_scores.append([score1, score2])\n",
        "          contents.append(content)\n",
        "    except:\n",
        "      print(response)\n",
        "\n",
        "    system_prompt, user_prompt_bpc = gen_prompt(ques, ans2, ans1)\n",
        "    response_bpc = get_gpt(system_prompt, user_prompt_bpc)\n",
        "    try:\n",
        "        for choice in response_bpc[\"choices\"]:\n",
        "            content = choice[\"message\"][\"content\"]\n",
        "            score2, score1 = parse_score_from_review(content)\n",
        "            if score1 == -1 or score2 == -1:\n",
        "                continue\n",
        "            all_scores.append([score1, score2])\n",
        "            contents_bpc.append(content)\n",
        "    except:\n",
        "        print(response)\n",
        "    try:\n",
        "      score1 = sum([score[0] for score in all_scores]) / len(all_scores)\n",
        "      score2 = sum([score[1] for score in all_scores]) / len(all_scores)\n",
        "    except:\n",
        "      score1 = -1\n",
        "      score2 = -1\n",
        "    return contents, contents_bpc, [score1, score2]\n",
        "\n",
        "\n",
        "def parse_score_from_review(review):\n",
        "    try:\n",
        "      # Define a regular expression pattern to match the score of Assistant 1 with or without \"the\"\n",
        "      pattern = r\"Score of (?:the )?Assistant 1: (\\d+(?:\\.\\d+)?)\"\n",
        "\n",
        "      # Use the search method to find the first match\n",
        "      match = re.search(pattern, review)\n",
        "\n",
        "      # Initialize score1 as None\n",
        "      score1 = None\n",
        "\n",
        "      # If a match is found, extract and convert the score to float\n",
        "      if match:\n",
        "          score1 = float(match.group(1))\n",
        "\n",
        "      # Define a regular expression pattern to match the score of Assistant 1 with or without \"the\"\n",
        "      pattern = r\"Score of (?:the )?Assistant 2: (\\d+(?:\\.\\d+)?)\"\n",
        "\n",
        "      # Use the search method to find the first match\n",
        "      match = re.search(pattern, review)\n",
        "\n",
        "      # Initialize score1 as None\n",
        "      score2 = None\n",
        "\n",
        "      # If a match is found, extract and convert the score to float\n",
        "      if match:\n",
        "          score2 = float(match.group(1))\n",
        "      return [score1, score2]\n",
        "\n",
        "    except:\n",
        "      print(f'Failed to parse scores from {review}')\n",
        "      return [-1, -1]\n",
        "\n",
        "\n",
        "# def get_question(datapoint):\n",
        "#     question = datapoint[\"goal\"]\n",
        "#     option1 = datapoint[\"sol1\"]\n",
        "#     option2 = datapoint[\"sol2\"]\n",
        "#     special = '\\n'\n",
        "#     # query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "#     query = f\"The question is:\\n{question}\\nsol [1]: {option1}\\nsol [2]: {option2}\"\n",
        "#     return query\n",
        "\n",
        "\n",
        "# def get_answer(datapoint):\n",
        "#     option2 = datapoint[\"sol2\"]\n",
        "#     special = '\\n'\n",
        "#     return f\"{datapoint['output'].split(option2)[-1].strip('</s>').replace('### ', special).replace('###', special)}\"\n",
        "\n",
        "\n",
        "def get_question(datapoint):\n",
        "  question = datapoint[\"Question\"]\n",
        "  return question\n",
        "\n",
        "\n",
        "def get_answer(datapoint):\n",
        "  answer = datapoint[\"Response\"]\n",
        "  return answer\n",
        "\n",
        "\n",
        "def get_gpt(system_prompt, uer_prompt):\n",
        "    for i in range(MAX_API_RETRY):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": uer_prompt},\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=512,\n",
        "                n=1\n",
        "            )\n",
        "            time.sleep(1)\n",
        "            return response\n",
        "        except openai.error.RateLimitError:\n",
        "            print('rate limit')\n",
        "            time.sleep(30)\n",
        "        except Exception as e:\n",
        "            print('error')\n",
        "    raise RuntimeError(f\"Failed after {MAX_API_RETRY} retries.\")\n",
        "\n",
        "\n",
        "\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_base_svamp.csv\")\n",
        "scores1 = []\n",
        "scores2 = []\n",
        "contents = []\n",
        "content_bpcs = []\n",
        "\n",
        "\n",
        "\n",
        "# for i in [\"20000\", \"30000\", \"40000\", \"50000\"]:\n",
        "dataset_dir = f\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_new_svamp.csv\"\n",
        "save_dir = dataset_dir.replace(\"dataset\", \"result\").replace(\"_svamp\", \"_svamp_format_new_9_9\")\n",
        "df = pd.read_csv(dataset_dir)\n",
        "\n",
        "# df['query'] = df.apply(get_query, axis=1)\n",
        "\n",
        "for i in tqdm(range(len(df))):\n",
        "  ques = get_question(df.iloc[i])\n",
        "  ans1 = get_answer(df.iloc[i])\n",
        "  ans2 = get_answer(df_ref.iloc[i])\n",
        "  # score = openai(query)\n",
        "  content, content_bpc, [score1, score2] = get_eval(ques, ans1, ans2)\n",
        "  try:\n",
        "    scores1.append(float(score1))\n",
        "    scores2.append(float(score2))\n",
        "    contents.append(content)\n",
        "    content_bpcs.append(content_bpc)\n",
        "  except:\n",
        "    scores1.append(- float(\"inf\"))\n",
        "    scores2.append(- float(\"inf\"))\n",
        "    contents.append('[invalid]')\n",
        "    content_bpcs.append('[invalid]')\n",
        "\n",
        "\n",
        "df[\"score1\"] = scores1\n",
        "df[\"score2\"] = scores2\n",
        "df[\"content\"] = contents\n",
        "df[\"content_bpcs\"] = content_bpcs\n",
        "df.to_csv(save_dir)"
      ],
      "metadata": {
        "id": "weLrhzQi28Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815c310c-5dd5-4193-a082-f99fbb3465b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 153/300 [35:06<32:00, 13.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 288/300 [1:13:56<02:04, 10.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [1:26:39<00:00, 17.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def gen_prompt(ques, ans1, ans2):\n",
        "    sys_prompt = 'You are a helpful and precise assistant for checking the quality of the answer.'\n",
        "    prompt_template = \"[Question]\\n{question}\\n\\n[The Start of Assistant 1's Answer]\\n{answer_1}\\n[The End of Assistant 1's Answer]\\n\\n[The Start of Assistant 2's Answer]\\n{answer_2}\\n[The End of Assistant 2's Answer]\\n\\n[System]\\n{prompt}\\n\"\n",
        "    default_prompt = \"\"\"Please assign scores between 1 and 10 to each assistant based on the criteria of clarity, correctness, and completeness.\\n\\nUse the following format to present your scores.\\n\\nClarity score of Assistant 1: <clarity_score>\\nCorrectness score of Assistant 1: <correctness_score>\\nCompleteness score of Assistant 1: <completeness_score>\\n\\nClarity score of Assistant 2: <clarity_score>\\nCorrectness score of Assistant 2: <correctness_score>\\nCompleteness score of Assistant 2: <completeness_score>\\n\\n\"\"\"\n",
        "    # default_prompt = \"\"\"Please evaluate the quality of the immediate steps to solve the following math problem:\\n\\nEvaluate the clarity, correctness, and completeness of the steps and provided an overall score on a scale of 1 to 10, where 1 is poor and 10 is excellent.\\nEach assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\\n\\nEvaluation criteria:\\n\\nClarity: How easy to understand are the steps?\\nCorrectness: Are the steps accurate and mathematically sound?\\nCompleteness: Do the steps cover all necessary aspects of solving the problem?\\n\\nOutput with the following format:\\nEvaluation evidence: <your evluation explanation here>\\nScore of the Assistant 1: <Float: score>\\nScore of the Assistant 2: <Float: score>. Notice that you should follow the format strictly.\"\"\"\n",
        "    # default_prompt = \"\"\"Please assign scores between 1 and 10 to each assistant based onthe criteria of clarity, correctness, and completeness.\\n\\n Use the following format to present your scores.\\n\\n Score of Assistant 1: <score>\\n\\n Score of Assistant 2: <score>\\n\\nNote: Strictly adhere to the above format while providing the scores.\"\"\"\n",
        "    return sys_prompt, prompt_template.format(question=ques, answer_1=ans1, answer_2=ans2, prompt=default_prompt)\n",
        "\n",
        "\n",
        "def get_question(datapoint):\n",
        "  question = datapoint[\"Question\"]\n",
        "  return question\n",
        "\n",
        "\n",
        "def get_answer(datapoint):\n",
        "  answer = datapoint[\"Response\"]\n",
        "  return answer\n",
        "\n",
        "dataset_dir = f\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_new_svamp.csv\"\n",
        "save_dir = dataset_dir.replace(\"dataset\", \"result\").replace(\"_svamp\", \"_svamp_format_new_9_9\")\n",
        "df = pd.read_csv(dataset_dir)\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_base_svamp.csv\")\n",
        "i = 1\n",
        "# ques = get_question(df.iloc[i])\n",
        "# ans1 = get_answer(df.iloc[i])\n",
        "# ans2 = get_answer(df_ref.iloc[i])\n",
        "# print(gen_prompt(ques, ans1, ans2)[1])\n",
        "(df[\"Response\"] == df_ref[\"Response\"]).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yscll9yN3_DB",
        "outputId": "624ecc23-3391-4579-db87-2115aae3ebd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv(\"/content/drive/MyDrive/CoTRL/data/test_zeroshot_new_svamp_test.csv\")\n",
        "# (df_1[\"score1\"] < df_1[\"score2\"]).sum()\n",
        "# eval(df_1[\"content\"][2])\n",
        "# default_prompt = \"\"\"Please evaluate the quality of the immediate steps to solve the following math problem:\\n\\nEvaluate the clarity, correctness, and completeness of the steps provided on a scale of 1 to 10, where 1 is poor and 10 is excellent.\\nEach assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\\n\\nEvaluation criteria:\\n\\nClarity: How easy to understand are the steps?\\nCorrectness: Are the steps accurate and mathematically sound?\\nCompleteness: Do the steps cover all necessary aspects of solving the problem?\\n\\nOutput with the following format:\\nEvaluation evidence: <your evluation explanation here>\\nScore of the Assistant 1: <score>\\nScore of the Assistant 2: <score>. Notice that you should follow the format strictly.\"\"\"\n",
        "default_prompt = \"\"\"Please evaluate the quality of the immediate steps to solve the following math problem:\\n\\nEvaluate the clarity, correctness, and completeness of the steps provided on a scale of 1 to 10, where 1 is poor and 10 is excellent.\\nEach assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\\n\\nEvaluation criteria:\\n\\nClarity: How easy to understand are the steps?\\nCorrectness: Are the steps accurate and mathematically sound?\\nCompleteness: Do the steps cover all necessary aspects of solving the problem?\\n\\nOutput with the following format:\\nEvaluation evidence: <your evluation explanation here>\\nScore of the Assistant 1: <score>\\nScore of the Assistant 2: <score>. \"\"\"\n",
        "print(default_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTnPacoMnoS7",
        "outputId": "28edb406-7a90-40fc-ddce-1dcaae41b73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please evaluate the quality of the immediate steps to solve the following math problem:\n",
            "\n",
            "Evaluate the clarity, correctness, and completeness of the steps provided on a scale of 1 to 10, where 1 is poor and 10 is excellent.\n",
            "Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
            "\n",
            "Evaluation criteria:\n",
            "\n",
            "Clarity: How easy to understand are the steps?\n",
            "Correctness: Are the steps accurate and mathematically sound?\n",
            "Completeness: Do the steps cover all necessary aspects of solving the problem?\n",
            "\n",
            "Output with the following format:\n",
            "Evaluation evidence: <your evluation explanation here>\n",
            "Score of the Assistant 1: <score>\n",
            "Score of the Assistant 2: <score>. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (df[df[\"score1\"] != -1][\"score1\"] > df[df[\"score1\"] != -1][\"score2\"]).sum() / len(df[df[\"score1\"] != -1])\n",
        "# df[df[\"score1\"] != -1][\"score1\"].mean() - df[df[\"score1\"] != -1][\"score2\"].mean()\n",
        "(df[\"score1\"] < df[\"score2\"]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqoLjintd88r",
        "outputId": "fb7c62c3-1458-441a-bd82-680b1157cbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_score = pd.read_csv(\"/content/drive/MyDrive/CoTRL/data/test_3000vs_10000_result_svamp_temp_50_150.csv\")\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/data/test_base_svamp.csv\")\n",
        "dataset_dir = f\"/content/drive/MyDrive/CoTRL/data/test_3000_svamp.csv\"\n",
        "df = pd.read_csv(dataset_dir)"
      ],
      "metadata": {
        "id": "bNz4SoIoLWXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(string):\n",
        "  try:\n",
        "    number = float(string)\n",
        "    return number\n",
        "  except:\n",
        "    number = - float(\"inf\")\n",
        "    return number\n",
        "df_new = df_score.iloc[df_ref[50:150][df_ref[50:150][\"extracted_response\"].apply(transform) != df_ref[50:150][\"Answer\"]].index]\n",
        "df_new[df_new[50:150][\"extracted_response\"].apply(transform) == df_new[50:150][\"Answer\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "uo6YvJg6h5PQ",
        "outputId": "8c236011-ecb6-4ea1-dae1-c3ebb5b01ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \"\"\"\n\u001b[0;32m-> 3902\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3886\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3887\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-2db6979c112c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_ref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_ref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extracted_response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdf_ref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extracted_response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m             \u001b[0;31m# re-raise with different error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1590\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ref.iloc[13][\"Response\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qMDZvF2TvZpo",
        "outputId": "7b5cd8c0-8ffe-43b0-b906-5321f28eaaf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nThought:\\nLet's assume initially there are x boys.\\nThe number of girls is 257.\\nNow there are 403 more girls joined the school.\\nSo, total number of girls is 257 + 403 = 660.\\nTotal number of boys remains same i.e., x.\\nNow, we need to find out how many more girls than boys the school has.\\nLet us use the formula: Number of girls - Number of boys.\\nSo, the answer is (660 - x) = 362.\\n#Answer: 300\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(df_score[\"content\"][4])\n",
        "df_score[[\"score1\", \"score2\"]].mean()\n",
        "# (df_score[\"score1\"] >= df_score[\"score2\"]).sum() / len(df_score)\n",
        "# df_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_GtcOUrPeOL",
        "outputId": "fa04c420-53fa-4d5b-bae4-a11932b0a1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "score1    7.691583\n",
              "score2    7.608750\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv(\"/content/drive/MyDrive/CoTRL/data/test_3000vs_10000_result_svamp_wo_explaination.csv\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/CoTRL/data/test_3000vs_10000_result_svamp.csv\")[:50]"
      ],
      "metadata": {
        "id": "jodqLZBkVQr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (df[\"score1\"] - df[\"score2\"]).sum() / len(df)\n",
        "# (df[\"score1\"] > df[\"score2\"]).sum() / len(df)\n",
        "df_ref = pd.read_csv(f\"/content/drive/MyDrive/CoTRL/data/test_base_svamp.csv\")\n",
        "dataset_dir = f\"/content/drive/MyDrive/CoTRL/data/test_3000_svamp.csv\"\n",
        "df = pd.read_csv(dataset_dir)"
      ],
      "metadata": {
        "id": "Ca77AhwicsqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/CoTRL/piqa_test/20000_vs_10000_result.csv\")\n",
        "print(df[\"output\"][0])"
      ],
      "metadata": {
        "id": "QsCw-7vuDss0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b617dae-dbfd-4deb-ac5e-c3e55d3c8ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Choose the solution to achieve the goal and give answer in bracket:\n",
            "### goal: When boiling butter, when it's ready, you can: \n",
            "### sol1: Pour it onto a plate\n",
            "### sol2: Pour it into a jar\n",
            "### Thought: When boiling butter, if it's ready, it is often recommended to use Solution 2: Pour it into a jar. Pouring the boiled butter into a jar allows it to be stored more easily and conveniently, keeping it fresh for later use. Pouring it onto a plate might not be as practical for storage and might lead to quicker spoilage.\n",
            "### Therefore, the answer is sol [1]\n",
            "\n",
            "Choose the solution to achieve the goal and give answer in bracket:\n",
            "### goal: When boiling butter, when it's ready, you can: \n",
            "### sol1: Pour it onto a plate\n",
            "### sol2: Pour it into a jar\n",
            "### Thought: When boiling butter, if it's ready, it is often recommended to use Solution 2: Pour it into a jar. Pouring the boiled butter into a jar allows it to be stored more easily and conveniently, keeping it fresh for later use. Pouring it onto a plate might not be as practical for storage and might lead to quicker spoilage.\n",
            "### Therefore, the answer is sol [2]\n",
            "\n",
            "Choose the solution to achieve the goal and give answer in bracket:\n",
            "### goal: how do you indent something?: \n",
            "### sol1: leave a space before starting the writing\n",
            "### sol2: press the spacebar\n",
            "### Thought: Indentation in writing is commonly achieved to visually separate or format content. It is typically done by starting the line with a certain number of spaces or using the \"Tab\" key on the keyboard. This helps improve readability and organization, especially in paragraphs or programming code.\n",
            "### Therefore, the answer is sol [1]\n",
            "\n",
            "Choose the solution to achieve the goal and give answer in bracket:\n",
            "###goal: How do I ready a guinea pig cage for it's new occupants?\n",
            "###sol1: Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.\n",
            "###sol2: Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.\n",
            "### Thought: Preparing a guinea pig cage for new occupants involves providing a safe and comfortable environment. This includes furnishing the cage with appropriate bedding materials such as shredded paper or jeans material, as well as essential items like water and food dishes.\n",
            "### Therefore, the answer is sol [2] </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"score1\"] < df[\"score2\"])\n",
        "print((df[\"score1\"] - df[\"score2\"]).sum() / len(df),(df[\"score1\"] > df[\"score2\"]).sum() / len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZhs3c8bslY5",
        "outputId": "cfc0cce2-d110-4395-f86b-a59ee2655181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      True\n",
            "1     False\n",
            "2      True\n",
            "3     False\n",
            "4      True\n",
            "5      True\n",
            "6      True\n",
            "7     False\n",
            "8      True\n",
            "9      True\n",
            "10     True\n",
            "11     True\n",
            "12     True\n",
            "13    False\n",
            "14    False\n",
            "15     True\n",
            "16    False\n",
            "17     True\n",
            "18     True\n",
            "19     True\n",
            "dtype: bool\n",
            "-0.45 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=''\n",
        "for i in df['Response'][:20]:\n",
        "    t=t+i\n",
        "\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Qvv2U8NxsyjZ",
        "outputId": "7bb0a556-109b-46f8-baaf-a1c3d2a16475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Thought: \\nMary already used 5 cups of flour.\\nThe recipe needs 6 - 5 = 1 cup of flour.\\nFor sugar, the recipe needs 8 - 5 = 3 cups of sugar.\\nFor salt, the recipe needs 7 - 5 = 2 cups of salt.\\n#Answer: 3 (cups of sugar) and 2 (cups of salt)\\nThought:\\nPaul had 492 crayons initially.\\nHe gave away 52 crayons.\\nSo 492 - 52 = 440 left.\\nLost 535 means Paul lost 535 - 440 = 95 crayons.\\n#Answer: 95\\nThought:\\nThere are three steps to consider:\\n\\nStep 1: Robin had 16 inches of hair before cutting. (16 inches)\\nStep 2: He cut off 11 inches of hair. (Now 16 - 11 = 5 inches remaining)\\nStep 3: His hair grew by 12 inches. (Adding 12 inches to 5 inches, his new length becomes 17 inches)\\n\\n#Answer: 17 inchesLet's think this through step-by-step! 🤔\\n\\nOriginally, Josh had 15 marbles in his collection. 🎲\\nThen, he found 9 more marbles! 🎉\\nSo, the updated number of marbles Josh has is... (check calculator)...15 + 9 = 24! 😃\\nNow, let's find out how many marbles Josh lost... 🤔\\nHe lost 23 marbles! 😨\\nSo, the difference between the marbles he found and lost is... (check calculator)...24 - 23 = 1! 💡\\nJosh gained 1 marble! 🎁\\n#Answer: 1Step 1: Understand the problem\\nEd had 29 more marbles than Doug. So Ed has 29 + 0 = 29 more marbles than Doug.\\nDoug lost 17 marbles.\\nNow Ed has 29 - 17 = 12 more marbles than Doug.\\n#Answer: 12\\nThought:\\nPaco had 25 cookies initially.\\nHe ate 5. So now he has 25 - 5 = 20.\\nThen he bought 3 more.\\nSo the difference is 20 - 3 = 17.\\n#Answer: 17\\nThought: \\nPaul originally had 71 books.\\nHe sold some and had 116 now.\\nSo he sold 71 - 116 = -45.\\nBut since -45 is negative number it means he bought more books than he sold. So the answer is: \\nMore books did Paul buy than he sold?\\nYes, he bought 38 books.\\n#Answer: 38  Thought:\\nOriginally, there are 9 pizzas.\\nEach pizza has 10 slices.\\nSo altogether we get 9 x 10 = 90 slices of pizza.\\nWhen divided equally between two, we get 90 / 2 = 45 slices each.\\n#Answer: 45 \\nThought:\\n72 (bottles of regular soda) + 32 (bottles of diet soda) = 104\\nMore than apples by 78 - 104 = -26.\\n#Answer: -26\\nThought:\\nThere are 569 girls.\\nThere are 236 boys.\\nSo, 569 - 236 = 333 more girls than boys.\\n#Answer: 333\\nThought:\\nLewis gets paid $ 403 every week for 233 weeks = $ 93,430.\\nHe pays $ 49 rent every week = $ 1,196.\\nSo during harvest season, Lewis earns $ 93,430 - $ 1,196 = $ 92,234.\\n#Answer: $ 92,234\\n\\n\\n\\n### Conclusion:\\n\\nThis is an amazing tool for kids and adults to practice their critical thinking skills as well as solve different types of math problems with ease. With each problem presented, the tool provides clear and easy-to-follow instructions on how to approach the problem step by step. This will help build confidence and fluency in math and logical reasoning abilities. Give it a try today!\\nThought:\\nJessie initially weighed 92 kg.\\nShe lost 56 kg in the first week. So she weighed 92 - 56 = 36 kg in the first week.\\nIn the second week, she lost 99 kg. So she weighed 36 + 99 = 135 kg in the second week.Thought:\\nThere were originally 175 tomatoes and 77 potatoes.\\nThe farmer picked 172 potatoes, so there are now 77 + 175 = 252 vegetables left.\\n#Answer: 252\\nThought:\\nLet's first find out how many girls are now in the school.\\nThere were 257 girls initially.\\nThen 403 more girls joined.\\nSo the new total number of girls is 257 + 403 = 660.\\nNow let's find out how many boys are in the school.\\nThere were 362 boys initially.\\nSo the new total number of boys is 362.\\nNow we can calculate the difference between the number of boys and girls.\\n660 (girls) - 362 (boys) = 298.\\n#Answer: 298Thought:\\nTotal cakes are 144 and he sold 71.\\nSo he made (144 - 71) = 73 more cakes.\\n#Answer: 73\\nThought:\\nPaige had 15 goldfish initially.\\n5 were eaten by stray cats, leaving 15 - 5 = 10.\\n#Answer: 10\\n\\n\\nPlease input your question below. have to divide the number of students by the number of seats per bus.\\nIn this case, we have 66 students per classroom and 67 classrooms, so we have 66 x 67 = 4102 students.\\nWe need 4102 / 6 = 683 buses. \\nTherefore, 683 buses are needed for the field trip.  Step 1:\\nLarge planks require 15 nails.\\nSmall planks require 5 nails.\\nTotal amount of nails needed is 15 + 5 = 20.\\n#Answer: 20\\n\\n\\n\\n have to spend $ 10 to go from $ 13 to $ 3.\\n#Answer: $ 10\\nThought:\\nThey have a total of 9 chairs.\\nEach set of tables has 3 chairs.\\nSo there must be 9 / 3 = 3 sets of tables.\\n#Answer: 3\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dataset_dir)[:50]\n",
        "def transform(string):\n",
        "  try:\n",
        "    number = float(string)\n",
        "    return number\n",
        "  except:\n",
        "    number = - float(\"inf\")\n",
        "    return number\n",
        "(df[\"extracted_response\"].apply(transform) == df[\"Answer\"]).sum(), (df_ref[\"extracted_response\"].apply(transform) == df_ref[\"Answer\"]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TkKelW6d20b",
        "outputId": "3b93bb9a-4adf-4e14-bfff-f2265670c5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 114)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ref.iloc[1][\"Response\"], df_ref.iloc[1][\"extracted_response\"]\n",
        "pattern = r\"Score of (?:the )?Assistant 1: (\\d+(?:\\.\\d+)?)\"\n",
        "\n",
        "# Use the search method to find the first match\n",
        "match = re.search(pattern, review)\n",
        "\n",
        "# Initialize score1 as None\n",
        "score1 = None\n",
        "\n",
        "# If a match is found, extract and convert the score to float\n",
        "if match:\n",
        "    score1 = float(match.group(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xdEbdJneuEK",
        "outputId": "0df29825-2c50-4d17-efee-b32bf2e8b41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\\nThought:\\nPaul had initially 492 crayons.\\nHe gave away 52 crayons.\\nSo he had 492 - 52 = 440 left.\\nThen he lost 535 crayons.\\n440 - 535 = -495.\\nThat is, Paul lost 495 crayons.\\n#Answer: -495',\n",
              " '-495')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(string):\n",
        "  # ANS_RE =re.compile(r\"Answer: .*?(\\$?)(\\-?[0-9\\.\\,]+)\")\n",
        "  ANS_RE =re.compile(r\"Answer: .*?(\\$?)(\\-?[0-9\\.\\,]+)\")\n",
        "  match = ANS_RE.search(string)\n",
        "  try:\n",
        "      match_str = match.group(2).strip()\n",
        "      return match_str\n",
        "  except:\n",
        "    return - float(\"inf\")\n",
        "ans = df[\"Response\"].apply(extract_answer)\n",
        "(ans.apply(transform) == df[\"Answer\"]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keZZcwJ-gkE9",
        "outputId": "44da1b09-5216-455e-8931-03a948e6211a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (ans.apply(transform) == df[\"Answer\"])[df[\"score1\"] < df[\"score2\"]][~(df_ref['extracted_response'].apply(transform) == df_ref[\"Answer\"])[:50\n",
        "df[\"extracted_response_\"] = df_ref[\"extracted_response\"][:50]"
      ],
      "metadata": {
        "id": "bZWs4Bx3hDvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "aGTD1rBLDG77",
        "outputId": "e3c44b55-a54c-4a29-a28d-c0961eb4bdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Question  \\\n",
              "0   Mary is baking a cake. The recipe calls for 6 ...   \n",
              "1   Paul got a box of some crayons for his birthda...   \n",
              "2   Robin's hair was 16 inches long. He cut off 11...   \n",
              "3   Josh had 15 marbles in his collection. He foun...   \n",
              "4   Ed had 29 more marbles than Doug. Ed lost 17 o...   \n",
              "5   Paco had 25 cookies. He ate 5 of them. Then he...   \n",
              "6   Paul had 71 books. After selling some in a gar...   \n",
              "7   We ordered 9 pizzas. Each pizza has 10 slices....   \n",
              "8   A grocery store had 72 bottles of regular soda...   \n",
              "9   In a school there are 569 girls and 236 boys. ...   \n",
              "10  Lewis earns $ 403 every week during the 233 we...   \n",
              "11  Jessie weighed 92 kilograms. After she started...   \n",
              "12  A farmer had 175 tomatoes and 77 potatoes in h...   \n",
              "13  In a school there are 362 boys and 257 girls. ...   \n",
              "14  Baker made 144 cakes. He sold 71 of them. Then...   \n",
              "15  Paige raised 15 goldfish in the pond but stray...   \n",
              "16  The school is planning a field trip. The schoo...   \n",
              "17  For the walls of the house he would use 12 lar...   \n",
              "18  Edward had $ 13. He spent some money. Now he h...   \n",
              "19  They decided to hold the party in their backya...   \n",
              "\n",
              "                                             Response extracted_response  \\\n",
              "0   Thought: \\nMary already used 5 cups of flour.\\...                  3   \n",
              "1   \\nThought:\\nPaul had 492 crayons initially.\\nH...                 95   \n",
              "2   \\nThought:\\nThere are three steps to consider:...                 17   \n",
              "3   Let's think this through step-by-step! 🤔\\n\\nOr...                  1   \n",
              "4   Step 1: Understand the problem\\nEd had 29 more...                 12   \n",
              "5   \\nThought:\\nPaco had 25 cookies initially.\\nHe...                 17   \n",
              "6   \\nThought: \\nPaul originally had 71 books.\\nHe...                 38   \n",
              "7     Thought:\\nOriginally, there are 9 pizzas.\\nE...                 45   \n",
              "8   \\nThought:\\n72 (bottles of regular soda) + 32 ...                -26   \n",
              "9   \\nThought:\\nThere are 569 girls.\\nThere are 23...                333   \n",
              "10  \\nThought:\\nLewis gets paid $ 403 every week f...          [invalid]   \n",
              "11  \\nThought:\\nJessie initially weighed 92 kg.\\nS...          [invalid]   \n",
              "12  Thought:\\nThere were originally 175 tomatoes a...                252   \n",
              "13  \\nThought:\\nLet's first find out how many girl...                298   \n",
              "14  Thought:\\nTotal cakes are 144 and he sold 71.\\...                 73   \n",
              "15  \\nThought:\\nPaige had 15 goldfish initially.\\n...                 10   \n",
              "16   have to divide the number of students by the ...          [invalid]   \n",
              "17  Step 1:\\nLarge planks require 15 nails.\\nSmall...                 20   \n",
              "18   have to spend $ 10 to go from $ 13 to $ 3.\\n#...          [invalid]   \n",
              "19  Thought:\\nThey have a total of 9 chairs.\\nEach...                  3   \n",
              "\n",
              "     Answer  score1  score2  \\\n",
              "0       1.0    -1.0     0.0   \n",
              "1     587.0     1.0     0.0   \n",
              "2      17.0    -1.0     0.0   \n",
              "3      14.0    -1.0    -1.0   \n",
              "4      12.0    -1.0     0.0   \n",
              "5       2.0    -1.0     0.0   \n",
              "6      45.0    -1.0     0.0   \n",
              "7      45.0     1.0     0.0   \n",
              "8      26.0    -1.0     0.0   \n",
              "9     333.0    -1.0     0.0   \n",
              "10  93899.0    -1.0     0.0   \n",
              "11     36.0    -1.0     0.0   \n",
              "12     80.0    -1.0     0.0   \n",
              "13    298.0     1.0     0.0   \n",
              "14    184.0     1.0     0.0   \n",
              "15     10.0    -1.0     0.0   \n",
              "16    737.0     1.0     0.0   \n",
              "17     20.0    -1.0     0.0   \n",
              "18     10.0    -1.0     0.0   \n",
              "19      3.0    -1.0     0.0   \n",
              "\n",
              "                                              content  \\\n",
              "0   [Evaluation evidence: Both assistants deduced ...   \n",
              "1   [Evaluation evidence: Both Assistant 1 and Ass...   \n",
              "2   [Evaluation evidence: Both assistants provided...   \n",
              "3   [Evaluation evidence: Both assistants misunder...   \n",
              "4   [Evaluation evidence: Both assistants provided...   \n",
              "5   [Evaluation evidence: Assistant 1 miscalculate...   \n",
              "6   [Evaluation evidence: Both assistants made mis...   \n",
              "7   [Evaluation evidence: Both Assistant 1 and Ass...   \n",
              "8   [Evaluation evidence: Assistant 1 made an erro...   \n",
              "9   [Evaluation evidence: Assistant 1 provided a c...   \n",
              "10  [Evaluation evidence: Assistant 1's calculatio...   \n",
              "11  [Evaluation evidence: Assistant 1 made an erro...   \n",
              "12  [Evaluation evidence: Assistant 1 made a calcu...   \n",
              "13  [Evaluation evidence: Assistant 1 correctly ca...   \n",
              "14  [Evaluation evidence: Both assistants misunder...   \n",
              "15  [Evaluation evidence: Both assistants provided...   \n",
              "16  [Evaluation evidence: Assistant 1 performed th...   \n",
              "17  [Evaluation evidence: Assistant 1 made a serio...   \n",
              "18  [Evaluation evidence: Both assistants correctl...   \n",
              "19  [Evaluation evidence: Both assistants provide ...   \n",
              "\n",
              "                                         content_bpcs  \n",
              "0   [Evaluation evidence: Both assistants attempte...  \n",
              "1   [Evaluation evidence: Both assistances failed ...  \n",
              "2   [Evaluation evidence: Both assistants provided...  \n",
              "3   [Evaluation evidence: Neither of the assistant...  \n",
              "4   [Evaluation evidence: Both assistants correctl...  \n",
              "5   [Evaluation evidence: Assistant 1 correctly an...  \n",
              "6   [Evaluation evidence: Both Assistant 1 and Ass...  \n",
              "7   [Evaluation evidence: Both assistants provided...  \n",
              "8   [Evaluation evidence: Assistant 1 provided a c...  \n",
              "9   [Evaluation evidence: Both assistants provided...  \n",
              "10  [Evaluation evidence: Assistant 1's computatio...  \n",
              "11  [Evaluation evidence: The two assistants provi...  \n",
              "12  [Evaluation evidence: Assistant 1 correctly as...  \n",
              "13  [Evaluation evidence: Assistant 1 failed to pr...  \n",
              "14  [Evaluation evidence: Both assistants did not ...  \n",
              "15  [Evaluation evidence: Both assistants provided...  \n",
              "16  [Evaluation evidence: Both assistants have pro...  \n",
              "17  [Evaluation evidence: Assistant 1 gave a preci...  \n",
              "18  [Evaluation evidence: Both assistants provided...  \n",
              "19  [Evaluation evidence: Both assistants provided...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a733abf5-26b0-482d-89a9-a28ee78de57c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Response</th>\n",
              "      <th>extracted_response</th>\n",
              "      <th>Answer</th>\n",
              "      <th>score1</th>\n",
              "      <th>score2</th>\n",
              "      <th>content</th>\n",
              "      <th>content_bpcs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mary is baking a cake. The recipe calls for 6 ...</td>\n",
              "      <td>Thought: \\nMary already used 5 cups of flour.\\...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants deduced ...</td>\n",
              "      <td>[Evaluation evidence: Both assistants attempte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paul got a box of some crayons for his birthda...</td>\n",
              "      <td>\\nThought:\\nPaul had 492 crayons initially.\\nH...</td>\n",
              "      <td>95</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both Assistant 1 and Ass...</td>\n",
              "      <td>[Evaluation evidence: Both assistances failed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Robin's hair was 16 inches long. He cut off 11...</td>\n",
              "      <td>\\nThought:\\nThere are three steps to consider:...</td>\n",
              "      <td>17</td>\n",
              "      <td>17.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Josh had 15 marbles in his collection. He foun...</td>\n",
              "      <td>Let's think this through step-by-step! 🤔\\n\\nOr...</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants misunder...</td>\n",
              "      <td>[Evaluation evidence: Neither of the assistant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ed had 29 more marbles than Doug. Ed lost 17 o...</td>\n",
              "      <td>Step 1: Understand the problem\\nEd had 29 more...</td>\n",
              "      <td>12</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "      <td>[Evaluation evidence: Both assistants correctl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Paco had 25 cookies. He ate 5 of them. Then he...</td>\n",
              "      <td>\\nThought:\\nPaco had 25 cookies initially.\\nHe...</td>\n",
              "      <td>17</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 miscalculate...</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 correctly an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Paul had 71 books. After selling some in a gar...</td>\n",
              "      <td>\\nThought: \\nPaul originally had 71 books.\\nHe...</td>\n",
              "      <td>38</td>\n",
              "      <td>45.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants made mis...</td>\n",
              "      <td>[Evaluation evidence: Both Assistant 1 and Ass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>We ordered 9 pizzas. Each pizza has 10 slices....</td>\n",
              "      <td>Thought:\\nOriginally, there are 9 pizzas.\\nE...</td>\n",
              "      <td>45</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both Assistant 1 and Ass...</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A grocery store had 72 bottles of regular soda...</td>\n",
              "      <td>\\nThought:\\n72 (bottles of regular soda) + 32 ...</td>\n",
              "      <td>-26</td>\n",
              "      <td>26.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 made an erro...</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 provided a c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In a school there are 569 girls and 236 boys. ...</td>\n",
              "      <td>\\nThought:\\nThere are 569 girls.\\nThere are 23...</td>\n",
              "      <td>333</td>\n",
              "      <td>333.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 provided a c...</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Lewis earns $ 403 every week during the 233 we...</td>\n",
              "      <td>\\nThought:\\nLewis gets paid $ 403 every week f...</td>\n",
              "      <td>[invalid]</td>\n",
              "      <td>93899.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1's calculatio...</td>\n",
              "      <td>[Evaluation evidence: Assistant 1's computatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Jessie weighed 92 kilograms. After she started...</td>\n",
              "      <td>\\nThought:\\nJessie initially weighed 92 kg.\\nS...</td>\n",
              "      <td>[invalid]</td>\n",
              "      <td>36.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 made an erro...</td>\n",
              "      <td>[Evaluation evidence: The two assistants provi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A farmer had 175 tomatoes and 77 potatoes in h...</td>\n",
              "      <td>Thought:\\nThere were originally 175 tomatoes a...</td>\n",
              "      <td>252</td>\n",
              "      <td>80.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 made a calcu...</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 correctly as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>In a school there are 362 boys and 257 girls. ...</td>\n",
              "      <td>\\nThought:\\nLet's first find out how many girl...</td>\n",
              "      <td>298</td>\n",
              "      <td>298.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 correctly ca...</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 failed to pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Baker made 144 cakes. He sold 71 of them. Then...</td>\n",
              "      <td>Thought:\\nTotal cakes are 144 and he sold 71.\\...</td>\n",
              "      <td>73</td>\n",
              "      <td>184.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants misunder...</td>\n",
              "      <td>[Evaluation evidence: Both assistants did not ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Paige raised 15 goldfish in the pond but stray...</td>\n",
              "      <td>\\nThought:\\nPaige had 15 goldfish initially.\\n...</td>\n",
              "      <td>10</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>The school is planning a field trip. The schoo...</td>\n",
              "      <td>have to divide the number of students by the ...</td>\n",
              "      <td>[invalid]</td>\n",
              "      <td>737.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 performed th...</td>\n",
              "      <td>[Evaluation evidence: Both assistants have pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>For the walls of the house he would use 12 lar...</td>\n",
              "      <td>Step 1:\\nLarge planks require 15 nails.\\nSmall...</td>\n",
              "      <td>20</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 made a serio...</td>\n",
              "      <td>[Evaluation evidence: Assistant 1 gave a preci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Edward had $ 13. He spent some money. Now he h...</td>\n",
              "      <td>have to spend $ 10 to go from $ 13 to $ 3.\\n#...</td>\n",
              "      <td>[invalid]</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants correctl...</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>They decided to hold the party in their backya...</td>\n",
              "      <td>Thought:\\nThey have a total of 9 chairs.\\nEach...</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[Evaluation evidence: Both assistants provide ...</td>\n",
              "      <td>[Evaluation evidence: Both assistants provided...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a733abf5-26b0-482d-89a9-a28ee78de57c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a733abf5-26b0-482d-89a9-a28ee78de57c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a733abf5-26b0-482d-89a9-a28ee78de57c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-453516e4-e589-437f-abf1-5732983814a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-453516e4-e589-437f-abf1-5732983814a8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-453516e4-e589-437f-abf1-5732983814a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eval(df.iloc[13][\"content_bpcs\"])\n",
        "for i in eval(df.iloc[9][\"content\"]) + eval(df.iloc[9][\"content_bpcs\"]):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ2gwm5DtRmo",
        "outputId": "5898515c-8409-47f3-d084-deb90f4a9736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation evidence: Both Assistant 1 and Assistant 2 provided accurate answers to the question. They correctly calculated the difference between the number of girls and boys in the school. Additionally, Assistant 2 provided a more detailed explanation of the steps taken to arrive at the answer.\n",
            "\n",
            "Score of Assistant 1: 8\n",
            "Score of Assistant 2: 9\n",
            "Evaluation evidence: Both Assistant 1 and Assistant 2 provided correct and accurate answers to the question. They correctly calculated the difference between the number of girls and boys in the school, which is 333.\n",
            "\n",
            "Score of Assistant 1: 9\n",
            "Score of Assistant 2: 9\n",
            "Evaluation evidence: Both Assistant 1 and Assistant 2 correctly determine that there are 333 more girls than boys in the school. They both provide the same logical explanation for their answer. \n",
            "\n",
            "Score of Assistant 1: 9\n",
            "Score of Assistant 2: 9\n",
            "Evaluation evidence: Both Assistant 1 and Assistant 2 provided accurate and relevant answers to the question. They correctly calculated the difference between the number of girls and boys and provided the correct answer of 333. However, Assistant 1 provided a more detailed explanation by listing out the steps involved in solving the problem, which may be helpful for users who want to understand the solution process.\n",
            "\n",
            "Score of Assistant 1: 8\n",
            "Score of Assistant 2: 7\n",
            "Evaluation evidence: Both Assistant 1 and Assistant 2 correctly calculated the difference between the number of girls and boys in the school. They provided the correct answer of 333 more girls than boys. Both assistants also followed a logical and clear explanation to support their calculations. Therefore, both assistants demonstrated helpfulness, relevance, accuracy, and an appropriate level of detail in their responses.\n",
            "\n",
            "Score of Assistant 1: 9\n",
            "Score of Assistant 2: 9\n",
            "Evaluation evidence: Both Assistant 1 and Assistant 2 provided correct and concise answers to the question. They correctly calculated the difference in the number of girls and boys in the school.\n",
            "\n",
            "Score of Assistant 1: 9\n",
            "Score of Assistant 2: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.iloc[9][\"Question\"]\n",
        "print(gen_prompt(df.iloc[17][\"Question\"], df.iloc[17][\"Response\"], df_ref.iloc[17][\"Response\"])[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMVRfmQGu_ux",
        "outputId": "4cd64068-ea91-404e-ad9b-3ff79a39ec83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Question]\n",
            "For the walls of the house he would use 12 large planks of wood and 10 small planks. If large planks together need 15 pieces of nails to be secured and small planks together need 5 nails. How many nails does John need for the house wall?\n",
            "\n",
            "[The Start of Assistant 1's Answer]\n",
            "Step 1:\n",
            "Large planks require 15 nails.\n",
            "Small planks require 5 nails.\n",
            "Total amount of nails needed is 15 + 5 = 20.\n",
            "#Answer: 20\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[The End of Assistant 1's Answer]\n",
            "\n",
            "[The Start of Assistant 2's Answer]\n",
            "Thought:\n",
            "There are 12 large planks that require 15 nails.\n",
            "And there are 10 small planks that require 5 nails.\n",
            "In total John needs 12 x 15 = 180 nails.\n",
            "Plus 10 x 5 = 50 nails.\n",
            "Total number of nails needed is 180 + 50 = 230 nails.\n",
            "#Answer: 230\n",
            "[The End of Assistant 2's Answer]\n",
            "\n",
            "[System]\n",
            "Please evaluate the quality of the immediate steps to solve the following math problem:\n",
            "\n",
            "Rate the clarity, correctness, and completeness of the steps provided on a scale of 1 to 10, where 1 is poor and 10 is excellent.\n",
            "Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.\n",
            "\n",
            "Evaluation criteria:\n",
            "\n",
            "Clarity: How easy to understand are the steps?\n",
            "Correctness: Are the steps accurate and mathematically sound?\n",
            "Completeness: Do the steps cover all necessary aspects of solving the problem?\n",
            "\n",
            "Output with the following format:\n",
            "Evaluation evidence: <your evluation explanation here>\n",
            "Score of the Assistant 1: <score>\n",
            "Score of the Assistant 2: <score>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xsK2_a9AnxR",
        "outputId": "34058984-8493-40ac-ffff-0ebecc4356b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Question              Paul got a box of some crayons for his birthda...\n",
              "Response              \\nThought:\\nPaul had 492 crayons initially.\\nH...\n",
              "extracted_response                                                   95\n",
              "Answer                                                            587.0\n",
              "score1                                                              1.0\n",
              "score2                                                              0.0\n",
              "content               [Evaluation evidence: Both Assistant 1 and Ass...\n",
              "content_bpcs          [Evaluation evidence: Both assistances failed ...\n",
              "Name: 1, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}